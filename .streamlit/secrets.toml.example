# .toml.example   (do NOT commit .toml)

# =========================
# OpenAI (default provider)
# =========================
OPENAI_API_KEY = "you-openai-api-key"
# Chat model options: gpt-4o, gpt-4o-mini (or your choice) 
OPENAI_CHAT_MODEL = "gpt-5-nano-2025-08-07"
# Embedding model options: text-embedding-3-small, text-embedding-3-large
OPENAI_EMBEDDING_MODEL = "text-embedding-3-small"

# =========================
# Supabase (server-side)
# =========================
SUPABASE_URL = ""
SUPABASE_ANON_KEY = ""
SUPABASE_SERVICE_KEY = ""

# ===========
# RAG tuning
# ===========
# If you reingest, you can experiment with 700–900 and overlap 120–150
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200
MAX_TOKENS_PER_CHUNK = 1500

# Retrieval (env-driven, no UI controls)
# Typical thresholds: 0.20–0.35. We recommend 0.25 to start.
SIMILARITY_THRESHOLD = 0.25
# How many chunks to keep in context
MAX_CONTEXT_CHUNKS = 10

# ========================
# Streamlit configuration
# ========================
# Azure sets $PORT; startup passes it to Streamlit
STREAMLIT_HOST = "0.0.0.0"
STREAMLIT_PORT = 8502        # used only for local dev
STREAMLIT_SERVER_HEADLESS = true
STREAMLIT_BROWSER_GATHER_USAGE_STATS = false

# ========================
# Authentication mode
# ========================
# Choose one:
#  - azure   → App Service Authentication (Entra ID / "Easy Auth")
#  - public  → no login required (local dev, quick demos)
#  - custom  → for plugging in your own provider (e.g., Auth0/Supabase Auth)
AUTH_MODE = "public"         #Adjusted for Streamlit deployment

# ========================
# Logging / runtime
# ========================
LOG_LEVEL = "INFO"
PYTHONUNBUFFERED = 1

